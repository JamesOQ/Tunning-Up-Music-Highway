{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba5eac-0b9f-4dc9-b318-cf4d4d63852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "\n",
    "# Load your data (this file must already include Latitude, Longitude, Date, and Time)\n",
    "df = pd.read_csv(\"datasets/Serious Injuries and Fatalities Data for I-40 Tennessee *with weather*.csv\")\n",
    "\n",
    "# Your Visual Crossing API key\n",
    "API_KEY = \"insert Vising Crossing API key here\"\n",
    "\n",
    "# Cache for already-queried (rounded_lat, rounded_lon, date) tuples\n",
    "wetness_cache = {}\n",
    "\n",
    "def extract_datetime(row):\n",
    "    try:\n",
    "        date_str = row['Collision_Date_Tooltip'].split('@')[0].strip()\n",
    "        date_obj = datetime.strptime(date_str, \"%A, %B %d, %Y\")\n",
    "        date_fmt = date_obj.strftime(\"%Y-%m-%d\")\n",
    "        time_str = row['Collision_Time_adj'].strip()\n",
    "        if time_str.lower() == \"unknown\":\n",
    "            return date_fmt, None\n",
    "        return date_fmt, time_str\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "def get_road_wetness(lat, lon, date_str, time_str):\n",
    "    base_url = \"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/\"\n",
    "    location = f\"{lat},{lon}\"\n",
    "    url = f\"{base_url}{location}/{date_str}?key={API_KEY}&unitGroup=us&include=hours\"\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                break\n",
    "            elif response.status_code == 429:\n",
    "                print(\" → Hit rate limit (429). Sleeping for 60 seconds...\")\n",
    "                sleep(60)\n",
    "            else:\n",
    "                return f\"HTTP {response.status_code}\"\n",
    "        except Exception as e:\n",
    "            return f\"Exception: {e}\"\n",
    "\n",
    "    try:\n",
    "        data = response.json()\n",
    "        hours = data['days'][0].get('hours', [])\n",
    "        if not hours:\n",
    "            return \"No hourly data\"\n",
    "\n",
    "        crash_time = datetime.strptime(time_str, \"%H:%M\")\n",
    "        crash_hour = round(crash_time.hour + crash_time.minute / 60)\n",
    "\n",
    "        # Accumulate precipitation over the 6 hours before and including crash time\n",
    "        start_hour = max(0, crash_hour - 6)\n",
    "        precip_total = 0.0\n",
    "        for h in hours[start_hour:crash_hour+1]:\n",
    "            try:\n",
    "                precip_total += float(h.get('precip', 0))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # Assign graded wetness level\n",
    "        if precip_total > 5:\n",
    "            return \"3 - Soaking\"\n",
    "        elif precip_total > 1:\n",
    "            return \"2 - Very Wet\"\n",
    "        elif precip_total > 0:\n",
    "            return \"1 - Damp\"\n",
    "        else:\n",
    "            return \"0 - Dry\"\n",
    "    except Exception as e:\n",
    "        return f\"Exception: {e}\"\n",
    "\n",
    "# Collect road wetness data\n",
    "wetness_levels = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    lat, lon = row['Latitude_adj'], row['Longitude_adj']\n",
    "    date_str, time_str = extract_datetime(row)\n",
    "    cache_key = (date_str, round(lat, 2), round(lon, 2))\n",
    "\n",
    "    print(f\"[{i+1}/{len(df)}] Getting road wetness for {date_str} {time_str or '[unknown]'} at ({lat},{lon})\")\n",
    "\n",
    "    if date_str and time_str:\n",
    "        if cache_key in wetness_cache:\n",
    "            wetness = wetness_cache[cache_key]\n",
    "            print(\" → (cached)\")\n",
    "        else:\n",
    "            wetness = get_road_wetness(lat, lon, date_str, time_str)\n",
    "            wetness_cache[cache_key] = wetness\n",
    "    else:\n",
    "        wetness = \"Missing or invalid time/date\"\n",
    "\n",
    "    print(f\" → Wetness: {wetness}\")\n",
    "    wetness_levels.append(wetness)\n",
    "\n",
    "    # Save partial results every 50 rows\n",
    "    if i > 0 and i % 50 == 0:\n",
    "        temp_df = df.iloc[:i+1].copy()\n",
    "        temp_df[\"Road_Wetness_Level\"] = wetness_levels\n",
    "        temp_df.to_csv(\"Map_Overview_with_Wetness_partial.csv\", index=False)\n",
    "        print(\"Saved checkpoint: Map_Overview_with_Wetness_partial.csv\")\n",
    "\n",
    "    sleep(2)\n",
    "\n",
    "# Final save\n",
    "df[\"Road_Wetness_Level\"] = wetness_levels\n",
    "df.to_csv(\"datasets/Serious Injuries and Fatalities Data for I-40 Tennessee *with weather and wetness*.csv\", index=False)\n",
    "print(\"File saved as Serious Injuries and Fatalities Data for I-40 Tennessee *with weather and wetness*.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa184f9a-4627-4b48-8ddd-1be55b81d02c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
